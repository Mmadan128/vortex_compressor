# Vortex-Codec â€” MI300X MAXIMUM config for ATLAS 200MB
# Push model size and batch to the limit on 192GB HBM3

model:
  d_model: 1024
  n_layers: 12
  n_heads: 16
  d_ff: 4096
  dropout: 0.1
  vocab_size: 256

compressive_memory:
  window_size: 1024
  compression_rate: 4

training:
  batch_size: 512
  learning_rate: 0.0015
  warmup_steps: 1000
  max_steps: 200000
  grad_clip: 1.0
  weight_decay: 0.01

dataset:
  window_size: 1024
  stride: 512
  max_bytes: null

evaluation:
  eval_interval: 500
  eval_batches: 100

compression:
  use_arithmetic_coding: true
  quantize_probabilities: false

logging:
  log_interval: 25
  save_interval: 1
  checkpoint_dir: "checkpoints"

hardware:
  device: "cuda"
  mixed_precision: true
  compile_model: false
